{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks Assessment\n",
    "\n",
    "This notebook will hold my solutions to the Tasks Assessment for Machine Learning and Statistics 2020.\n",
    "\n",
    "\n",
    "The author is Angela Carpenter\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Task 1: Calculate the square root of two to 100 decimal places without using any imported module](#task-1)\n",
    "\n",
    "\n",
    "- [Task 2: Chi-squared test for Independence](#task-2)\n",
    "\n",
    "- [Task 3 - Standard Deviation Functions](#task-3)\n",
    "\n",
    "- [Task 4 - not yet released](#task-4)\n",
    "\n",
    "- [References](#references)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan\n",
    "- Cut more from task 1! \n",
    "- Add some more references for task 2 rather than just referring old college notes.\n",
    "- alpha level, p-value etc\n",
    "- Tidy up references, keep numbering consistent.\n",
    "- Task 3 Standard deviation \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Write a Python function called sqrt2 that calculates and prints to the screen the square root of 2 to 100 decimal places. Your code should not depend on any module from the standard library or otherwise. You should research the task first and include references and a description of your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The square root of two $\\sqrt{2}$\n",
    "In mathematics, a square root of a number $x$ is a number $y$ such that $y2 = x$; in other words, a number $y$ whose square (the result of multiplying the number by itself, or $y⋅y$) is $x$. [1][Wikipedia](https://en.wikipedia.org/wiki/Square_root).\n",
    "The principal square root function $f(x) = \\sqrt{x}$ is a function that maps the set of nonnegative real numbers onto itself. In geometrical terms, the square root function maps the area of a square to its side length.\n",
    "\n",
    "The square root of two is the number that when multiplied by itself gives the number two. The length of the diagonal of a square where each side of the square is of length 1 is the square root of the number 2 (Pythagoras theorem).\n",
    "\n",
    "According to [2][Wikipedia](https://en.wikipedia.org/wiki/Square_root_of_2)., the square root of two was probably the first number known to be irrational.\n",
    ">*The square root of 2, or the one-half power of 2, written in mathematics as \n",
    "$2{\\sqrt {2}}$ or $2^{{1/2}}$ is the positive algebraic number that, when multiplied by itself, equals the number 2.*\n",
    ">Technically, it must be called the principal square root of 2, to distinguish it from the negative number with the same property.\n",
    "[2][Wikipedia](https://en.wikipedia.org/wiki/Square_root_of_2).\n",
    "\n",
    "\n",
    "An **irrational** number is one which cannot be expressed as a ratio of two numbers, i.e. a fraction.\n",
    "Any number that can be expressed as a ratio of two integers, a decimal that either ends or repeats in a recurring manner or a percentage is said to be a rational number. All whole numbers are rational as they can be represented as fractions divided by 1. \n",
    "\n",
    "Greek mathematicians such as Pythagoras had believed that all numbers could be shown to be fractions, believing that the number line was made up entirely of fractions, because for any two fractions we can always find another fraction in between them. Because this process has no end there are infinitely many such points. \n",
    "Hippasus [4][The Maths Book: Big Ideas Simply explained](published by Dorling Kindersley Limited), a Greek scholar is believed to have first identified irrational numbers in the 5th century BCE as he worked on geometrical problems. He applied Pythagoras's theorem which states that the square of the hypothenuse in a triangle is equal to the sum of the squares of the other two sides, to a right-angled triangle with both shorter sides equal to one. Hippasus realised that the length of the hypothesus of such as triangle was equal to the square root of two but that the square root of two could not be expressed as a ratio of two whole numbers, as a fraction. There is no rational number which can be multiplied by itself to give precisely two which means that the square root of two an irrational number. The number two is termed non-square or square free. The numbers 3, 5 and 7 and many others are also non-square with irrational square roots. Numbers such as 4, 9 and 16 are square numbers and do have square roots that are also whole numbers and therefore rational.\n",
    "\n",
    "Another rational number can always be found in between two rational numbers. The average of the two numbers will also be rational. The average of the number and either of the two original numbers will be rational. Irrational numbers can also be found in between any two rational numbers. There are infinite numbers of rational numbers and infinite numbers of irrational numbers but the \n",
    "\n",
    "A real number gives a positive result when squared. The square root of two gives a positive result when squared of 2. An irrational number has an infinite number of decimals with no recurring pattern. This is the case for the square root of two.  The square root of 2 truncuated to 50 decimal places is 1.41421356237309504880168872420969807856967187537694\n",
    "See (https://en.wikipedia.org/wiki/Square_root).The square root of 2 is a real number that is not rational.\n",
    "\n",
    "\n",
    "The square root of $x$ is **rational** if and only if $x$ is a rational number that can be represented as a ratio of two perfect squares.\n",
    "A positive number has two square roots, one positive and one negative which are opposite each other but when talking of the square root of a positive integer it is usually just the positive square root that is meant.\n",
    "The square root of a positive integer is the product of the roots of its prime factors, because the square root of a product is the product of the square roots of the factors.\n",
    "\n",
    "The square roots of perfect squares such as 1, 4, 9 and 16 are integers. In all other cases, the square roots of positive integers are irrational numbers, and therefore have non-repeating digits in any standard positional notation system.\n",
    "\n",
    "The value of the square root of two cannot be determined accurately because it cannot be represented as a fraction in the form a/b where a and b are whole numbers and has an infinite number of decimals.[3][geeksforgeeks](https://www.geeksforgeeks.org/square-root-of-2/)\n",
    "\n",
    "In mathematics, the natural numbers are those used for counting and ordering. Some definitions begin the natural numbers at 0 corresponding to non-negative integers 0,1,2,3... collectively denoted by $\\mathbb{N_0}$  while others start with 1, corresponding to the positive integers 1,2,3,... collectively denoted by $\\mathbb{N_1}$. The natural numbers are the basis from which other number sets are built by extension. Natural numbers are often known as the counting numbers (excluding negative integers and zero) and are discrete numbers in contrast to measuring numbers or real numbers where the values are continuous and represent a distance along a line. Real numbers can be represented as an inifinite decimal expansion.\n",
    "\n",
    "####  Binary representation of integers and floats and what this means for the square root of two.\n",
    "In terms of computing, computer programs are made up of binary strings of 1's and 0's which can be converted into integers. Every computer program can be converted into one of the counting numbers from the set of $\\mathbb{N}$ . According to Turing, all computer programs are countable which means they can be put into one-to-one correspondance with the natural numbers but Turing also realised that not all numbers can be calculated or computed.[Lectures notes by Ian Mc Loughlin]. The set of $\\mathbb{N}$ Natural numbers are an infinite set but it is the smallest infinite set there is and is known as countable infinite. The set of measuring numbers are all the numbers on the number line that are used for quantifying and measuring things and there is an infinite amount of such numbers between any two discrete points on the number line.\n",
    "\n",
    "A rational number can be expressed as the ratio of 2 whole numbers. It can be stored as an array of two numbers. (A number is rational only if it's decimal expansion becomes periodic).\n",
    "Real numbers such as $\\sqrt{2}$ have an infinite number of places after the decimal point. Computers cannot really store such real numbers as there is only a finite number of bits available to store the number.\n",
    "\n",
    "Floating point numbers are stored on a computer with a finite number of digits so there is a finite limit on how many decimal places they can actually store. Floating point numbers are actually stored using integers in two parts, for the whole number part before the decimal point (the characteristics) and the part of the whole after the decimal point (the mantissa). \n",
    "\n",
    "The square root of two is an irrational number and therefore cannot be expressed in the ratio of two numbers in their most simplified form with the resulting implications being that the square root of two can never be stored in a computer. Instead an approximation of its value can be stored (in the same way an approximation for the irrational number $pi$ is stored). Irrational numbers are often stored as procedures which are used to calculate but not store the number.\n",
    "\n",
    "For this reason caution is always required when calculation statistics or performing analytics on irrational numbers. It is possible to work theoretically or to use approximations but rounding errors could interfere will the calculations.\n",
    "\n",
    "[Chapter 5 of the Python Tutorial](https://docs.python.org/3/tutorial/floatingpoint.html) looks at the issues and limitations associated with floating point arithmetic. It illustrates how the decimal fraction 0.125 and the binary fraction 0.001 have identical values:\n",
    "\n",
    "- Floating-point numbers are represented in computer hardware as base 2 (binary) fractions\n",
    "- The decimal fraction 0.125 has value $\\frac{1}{10}$ + $\\frac{2}{100}$ + $\\frac{5}{1000}$\n",
    "- The binary fraction 0.001 has value $\\frac{0}{2}$ + $\\frac{0}{4}$ + $\\frac{1}{8}$\n",
    "The only real difference here is that the decimal fraction 0.125 is written in base 10 fractional notation while the binary fraction 0.001 above is written in base 2 notation.\n",
    "\n",
    ">Unfortunately, most decimal fractions cannot be represented exactly as binary fractions. A consequence is that, in general, the decimal floating-point numbers you enter are only approximated by the binary floating-point numbers actually stored in the machine.\n",
    "\n",
    "(It demonstrates how the fraction 1/3 can be approximated as a base 10 fraction as  0.3 or 0.33 or 0.333. No matter how many 3's you use the result will never actually be $\\frac{1}{3}$ but it will be increasingly a better approximation of $\\frac{1}{3}$)\n",
    "\n",
    "The decimal value 0.1 cannot be represented exactly as a base 2 fraction because in base 2, $\\frac{1}{10}$ is the infinitely repeating fraction\n",
    "0.0001100110011001100110011001100110011001100110011...\n",
    "If you stop at any  finite number of bits you get an approximation. \n",
    "On most machines today floats are approximated using a binary fraction. \n",
    "- The numerator uses the first 53 bits starting with the most significant bit\n",
    "- The denominator as a power of 2\n",
    "The binary fraction for the decimal 0.1 is `3602879701896397 / 2 ** 55` which is close to the true value of 1/10 but it is not exactly equal to the true value of 0.1.\n",
    "We don't notice that this is not the true value and only an approximation because of the way values are displayed. Python (and other languages) only prints *a decimal approximation to the to the true decimal value of the binary approximation stored by the machine* \n",
    "\n",
    "- The true decimal value of the binary approximation stored for 0.1 is actually `0.1000000000000000055511151231257827021181583404541015625`. It is printed as 0.1 though.\n",
    "- Python displays a rounded value instead of all the digits as in most situations this is enough.\n",
    "- The important point is that even though what we see printed (0.01) looks like the exact value of $\\frac{1}{10}$, the actual value that is stored is the nearest representable binary fraction.\n",
    "\n",
    "- The Python docs tutorial also illustrates how there are many different decimal numbers which actually share the same nearest approximate binary fraction. The numbers `0.1`  and `0.10000000000000001` and `0.1000000000000000055511151231257827021181583404541015625` are all approximated by `3602879701896397 / 2 ** 55` . These decimal values all have the same approximation.\n",
    "\n",
    "- String formatting can be used to produce a limited number of significant digits.\n",
    "For example `format(math.pi, '.12g')` gives 12 significant digits while `format(math.pi, '.2f')` gives 2  digits after the point.\n",
    "However this is simply rounding the **display** of the true machine value.\n",
    "\n",
    "See [The Perils of Floating Point](http://www.lahey.com/float.htm)\n",
    "See [str.format](https://docs.python.org/3/library/stdtypes.html#str.format)\n",
    "\n",
    "The errors in Python float operations come from the floating-point hardware. \n",
    ">The errors in Python float operations are inherited from the floating-point hardware, and on most machines are on the order of no more than 1 part in `2**53` per operation. That’s more than adequate for most tasks, but you do need to keep in mind that it’s not decimal arithmetic and that every float operation can suffer a new rounding error. (Chapter 5)\n",
    "\n",
    "**Representation error** refers to the fact that most decimal fractions cannot be represented exactly as binary (base 2) fractions in Python and other languages and therefore won’t display the exact decimal number you expect.\n",
    "- Most machines use IEEE-754 floating point arithmetic.\n",
    "- Almost all platforms map Python floats to IEEE-754 “double precision”.\n",
    "- 754 doubles contain 53 bits of precision. \n",
    "The computer strives to convert 0.1 to the closest fraction that it can of the form $J/2**N$ where J is an integer containing exactly 53 bits.\n",
    "\n",
    "- See [IEEE 754](https://en.wikipedia.org/wiki/IEEE_754) and [IEEE Standard 754 Floating Point Numbers](https://www.geeksforgeeks.org/ieee-standard-754-floating-point-numbers/) article on <geeksforgeeks.com>.\n",
    "- IEEE 754 has 3 basic components:\n",
    "    * The sign of the mantissa where `0` represents a positive number while `1` represents a negative number.\n",
    "    * The biased exponent\n",
    "    * The Normalised Mantissa\n",
    "\n",
    "- The [decimal module](https://docs.python.org/3/library/decimal.html#module-decimal) implements decimal arithmetic suitable for accounting applications and high-precision applications.\n",
    "- The [fractions module](https://docs.python.org/3/library/fractions.html#module-fractions)  implements arithmetic based on rational numbers (so the numbers like 1/3 can be represented exactly).\n",
    "- NumPy and [scipy](https://scipy.org) packages are recommended for mathematical and statistical operations.\n",
    "- Python also has a [float.as_integer_ratio()](https://docs.python.org/3/library/stdtypes.html#float.as_integer_ratio) method which expresses the value of a float as a fraction. This can help when you want to know the exact value as a float. As the ratio is exact, it can be used to losslessly recreate the original value.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Both Python's `math` module and the `numpy` library have a function called `sqrt` for calulating square roots.\n",
    "This task should not use any libraries but they can be used to check the code.\n",
    "`math.sqrt(x)` calculates the square root of whatever is passed in as `x`.\n",
    "This task however is to calculate the square root of the number 2 to 100 decimal places. \n",
    "The square root of a number when multiplied by itself should give the number so here I check that by multiplying the result of `math.sqrt(2)` by `math.sqrt(2)`.\n",
    "\n",
    "The results below of squaring the square root of two returned from both the `math.sqrt` function and the `np.sqrt` function is 2.0000000000000004.  This demonstrates the problem with performing calculations on the irrational number square root of two!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will delete all this below but leaving here for my reference for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2.0000000000000004\n",
      "1.4142135623730951\n",
      "2.0000000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import math module\n",
    "import math\n",
    "# using the sqrt function\n",
    "print(math.sqrt(2))\n",
    "print(math.sqrt(2)*math.sqrt(2))\n",
    "import numpy as np\n",
    "print(np.sqrt(2))\n",
    "print(np.sqrt(2)*np.sqrt(2))\n",
    "np.sqrt(2)*np.sqrt(2)==2\n",
    "# just seeing if the numpy and math square roots are the exact same\n",
    "math.sqrt(2) == np.sqrt(2)\n",
    "math.sqrt(2)*math.sqrt(2) == np.sqrt(2)*np.sqrt(2)\n",
    "x = np.sqrt(2)\n",
    "x.as_integer_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for Calculating square roots\n",
    "Finding the square root of a number is the inverse of finding the square of a number. The square of a number is the number times itself. The perfect squares are the squares of the whole numbers. The square root of a number is the number that when multiplied by itself gives the number.\n",
    "\n",
    ">*The square roots of the perfect squares (e.g., 0, 1, 4, 9, 16) are integers. In all other cases, the square roots of positive integers are irrational numbers, and hence have non-repeating decimals in their decimal representations.* [2]  <https://en.wikipedia.org/wiki/Square_root>\n",
    "\n",
    "\n",
    "While getting the square root of the perfect squares is straightforward enough, getting the square root of numbers that are not perfect squares is not so. A manual calculation would start by looking at the square roots of the nearest perfect squares on either side of the number in question and involves some guesswork to begin. The Babylonian method of guess and divide takes a starting estimate to the square root ($x_0$), divides this starting estimate into the number $a$ whose square root you are looking for and then finds the average of the quotient $x_0$ and the divisor $a$ to get the next estimate $x_{0+1}$.\n",
    "\n",
    "### Calculate the square root of number using Babylonian method\n",
    "Finding the square root of a number that is not a whole number begins with some guesswork. Begin by looking at the nearest perfect squares on both sides of the number to make a starting guess of what the square root could be.\n",
    "The Babylonian method of guess and divide takes a starting estimate to the square root ($x_0$), divides this starting estimate into the number $a$ whose square root you are looking for and then finds the average of the quotient $x_0$ and the divisor $a$ to get the next estimate $x_{0+1}$.\n",
    "\n",
    "The post here at https://blogs.sas.com/content/iml/2016/05/18/newtons-method-babylonian-square-root.html explains simply how the algorithm taught in school for calculating the estimating a square root from an arbitrary guess is an iterative procedure. Given any positive number $S$ and any positive number $x_0$, apply the following formula:\n",
    "$$x_{n+1} = \\frac{(x_n + S/x_n)}{2}$$ until the iteration converges to the square root of $S$.\n",
    " \n",
    "The same author has a post on the [Babylonian method for finding square roots by hand](https://blogs.sas.com/content/iml/2016/05/16/babylonian-square-roots.html). (This seems to be the way I was trying to work out below.)\n",
    "Suppose you are given any positive number $S$. To find it's square root do the following:\n",
    "1. Make an initial guess. This guess can be any positive number. This is $x_0$\n",
    "2. Improve the guess by applying the formula $x_1 = \\frac{(x_0 + \\frac{S}{x_0})}{2}$.\n",
    "   The number $x_1$ is a better approximation to the square root of $S$.\n",
    "3. Iterate until convergence. \n",
    "   Apply the formula $x_{n+1}=\\frac{(x_n+\\frac{S}{x_n})}{2}$ until the process converges.\n",
    "\n",
    "    * Convergence is achieved when the  digits of $x_{n+1}$ and $x_n$ agree to as many decimal places as you desire.\n",
    "    \n",
    "#### Applying this logic to get the square root of 2\n",
    "\n",
    "First make a guess of what the root of the number in question could be based on the square root of the nearest perfect squares on either side.  Add the result of this to the number and question and divide by two to get the average as the new starting guess. Keep repeating.\n",
    "\n",
    "1. Find two perfect square roots that the number in question lies between. \n",
    " \n",
    "2. Take one of those square roots as an estimate and divide the number in question by it.\n",
    "    * S = 2\n",
    "    * The square root of 2 must lie between 1 and 2\n",
    "    * Taking 1 here as the estimate $x_0=1$\n",
    "    * Divide number in question by the starting estimate S/x0 = 2/1 = 2 = X1\n",
    "    \n",
    "3. Take the average of the latest estimate x1 (2) and S (from the previous step above) and the Number.\n",
    "\n",
    "    * x1 = (x0 +S/x0)/2 = (2 + 2/1)/2 = 2\n",
    "    * x2 = (x1 + S/x1)/2 = (2 + 2/2)/2 =1.5\n",
    "    * x3 = (x2 + S/x2)/2 = (1.5 + 2/1.5)/2 = 1.4166666666666665\n",
    "    * x4 = (x3 + S/x3)/2 = (1.4166666666666665 + 2/1.4166666666666665)/2 = 1.4142156862745097\n",
    "    * x5 = (x4 + S/x4)/2 = (1.4142156862745097 + 2/1.4142156862745097)/2 = 1.4142135623746899\n",
    "    * x6 = (x5 + S/x5)/2 = (1.4142135623746899 + 2/1.4142135623746899)/2 = 1.414213562373095\n",
    "    * x7 = (x6 + S/x6)/2 = (1.414213562373095 + 2/1.414213562373095)/2   = 1.414213562373095\n",
    "    * x8 = (x7 + S/x7)/2 = (1.414213562373095 + 2/1.414213562373095)/2   = 1.414213562373095\n",
    "    * x9 = (x8 + S/x8)/2 = (1.414213562373095 + 2/1.414213562373095)/2   = 1.414213562373095\n",
    "    \n",
    "    `math.sqrt(10)` gives 3.1622776601683795 \n",
    "\n",
    "As the illustration shows here, once you get to the 5th iteration, the result is truncuated or rounded. (which?)\n",
    "- The square root of 2 truncuated to 50 decimal places is 1.41421356237309504880168872420969807856967187537694\n",
    "See (https://en.wikipedia.org/wiki/Square_root).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142156862745097\n",
      "1.4142135623746899\n",
      "1.414213562373095\n",
      "1.414213562373095\n",
      "1.414213562373095\n"
     ]
    }
   ],
   "source": [
    "#print(f\"{(3.16666667 + (10/3.1666667))/2}\")\n",
    "#print(f\"{(3.162280686800554 +10/3.162280686800554)/2}\")\n",
    "#print(f\"{(3.1622776601698277 + 10/3.1622776601698277)/2}\")\n",
    "#print(f\"{(3.162277660168379 + 10/3.162277660168379)/2 }\")\n",
    "\n",
    "print(f\"{(1.4166666666666665 + 2/1.4166666666666665)/2}\")\n",
    "print(f\"{(1.4142156862745097 + 2/1.4142156862745097)/2}\")\n",
    "print(f\"{(1.4142135623746899 + 2/1.4142135623746899)/2}\")\n",
    "print(f\"{(1.414213562373095 + 2/1.414213562373095)/2}\")\n",
    "print(f\"{(1.414213562373095 + 2/1.414213562373095)/2}\")\n",
    "# and on until you get the required accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Newton's Method\n",
    "Newtons Method which is also known as the Newton–Raphson method, can be used to get an estimate of the square root of a number.  It is a root-finding algorithm which produces successively better approximations to the roots (or zeroes) of a real-valued function. [Newton's Method](https://en.wikipedia.org/wiki/Newton%27s_method) is one of many methods of computing square roots and is outlined in detail in the Wikipedia article. It outlines how the problem of finding the square root of a number $a$ can be rephrased as finding the zero of $f(x)=x2−a$ where $f$ is a single-variable function defined for a real variable $x$, with an initial guess of $x_0$ for a root of $f$. The derivative of the function $f'(x)=2x$. Rearranging the formula yields the Babylonian method of finding square roots :\n",
    "\n",
    "$$x_{n+1}=x_{n}-{\\frac{f(x_{n})}{f'(x_{n})}}=x_{n}-{\\frac{x_{n}^{2}-a}{2x_{n}}}={\\frac {1}{2}}{\\biggl(}2x_{n}-{\\Bigl(}x_{n}-{\\frac{a}{x_{n}}}{\\Bigr)}{\\biggr)}={\\frac {1}{2}}{\\Bigl(}x_{n}+{\\frac {a}{x_{n}}}{\\Bigr )}$$\n",
    "\n",
    "i.e. the arithmetic mean of the guess, $x_n$ and $\\frac{a}{x_n}$\n",
    "\n",
    "\n",
    "Using Newtons Method, regardless of the starting estimate, once the square of the estimate gets close enough to the actual number itself, then that is considered a good approximation for the square root.\n",
    "\n",
    "https://math.mit.edu/~stevenj/18.335/newton-sqrt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding up the square root function using methods above.\n",
    "\n",
    "Newton's method or the Babylonian method can be put into code using an iterative algorithm.\n",
    "\n",
    "- $S$ represents the number whose square root is being sought. (This is $a$ in the formula above)\n",
    "- $x$ represents the changing estimates ($x_n$, $x_0$, $x_1$, $x_{n+1}$ for the estimates at each step). \n",
    "- The algorithm takes the average of the estimate  $x_n$ and the number  $S$ divided by the estimate $x_n$. This will give a new estimate for the next iteration $x_{n+1}$.\n",
    "- The values of the estimate $x$ is updated at each iteration of a while loop representing the $X_n$ and $x_{n+1}$ estimates.\n",
    "\n",
    "The most digits this function yielded was 15 decimal places. While the algorithm itself will calculate approximately the square root of two (accurate to 15 digits at least), it will not print out 100 decimal places so easily. \n",
    "At some stage the result gets rounded and this is the main issue as outlined earlier when dealing with real numbers. Wikipedia records the square root of 2 to 50 decimal places as `1.41421356237309504880168872420969807856967187537694`.\n",
    "Numpy's `sqrt` function returns the same answer as my function above to 15 decimal places. The square root of 2 using `np.sqrt` to 50 decimal places is 1.41421356237309514547462185873882845044136047363281 which differs from that recorded at Wikipedia.\n",
    "\n",
    "I did try to increase the precision of the while loop to see if this would yield additional digits but the maximum was still  only 15 decimal places. This is as expected given the background of how computers deal with floating point numbers. \n",
    "The[Python docs section on on floating points numbers.](https://docs.python.org/3/tutorial/floatingpoint.html) \n",
    ">Unfortunately, most decimal fractions cannot be represented exactly as binary fractions. A consequence is that, in general, the decimal floating-point numbers you enter are only approximated by the binary floating-point numbers actually stored in the machine.\n",
    "According to the Python Docs section on [numeric types](https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex) integers have unlimited precision.\n",
    "\n",
    "Therefore the next logical step was to apply the function to a very large integer multiple of 2 as this would not have the same limitations as floats and then divide the result by the same integer multiple. The whole number before the decimal point cannot be rounded. In the same way that the square root of 4 is 2, the square root of 400 is 20, and so on. In this way the digits of the square root of two could be produced but with the decimal point in the incorrect place. Some string manipulation then to return the correct result.\n",
    "\n",
    "Another option was applying the power of 1/2 to get the square root and applying this to a large multiple of 2 but again this returns scientific notation after the 15th decimal place.\n",
    "\n",
    "Applying either Newtons formula or the equivalent Babylonian guess and divide formula resulted in 1.4142135623730951 being returned as the approximate square root of two (using precision of 0.0000000000001 to stop the while loop.)\n",
    "Applying the function to get the square root of 2e200 gave the result in scientific notation. Therefore the 100 digits cannot be extracted at this stage.\n",
    "Nevertheless I compared the results to math.sqrt to see how they fare and the results are the same.\n",
    "Python only prints a decimal approximation to the true decimal value of the binary approximation stored by the machine. (https://docs.python.org/3/tutorial/floatingpoint.html).  While the printed result might look like the exact value, the actual stored value is the nearest representable binary fraction. While string formatting can be used to produce a limited number of significant digits, you are really just rounding the display of the true machine value. \n",
    ">The errors in Python float operations are inherited from the floating-point hardware, and on most machines are on the order of no more than 1 part in `2**53` per operation. That’s more than adequate for most tasks, but you do need to keep in mind that it’s not decimal arithmetic and that every float operation can suffer a new rounding error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.414213562373095e+19"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200000000000000000000000000000000000000**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# S is number to get square root of, S= 2\n",
    "def sqrtn():\n",
    "    \n",
    "    # take the first estimate x to be the number itself\n",
    "    S=2\n",
    "    x = S \n",
    "    \n",
    "    # repeat this until the difference between the Estimate Squared minus the number is small enough\n",
    "    # without setting a stopping value here, the loop will continue for a long time\n",
    "    while abs(x*x - S) > 0.000000000001:\n",
    "        # Update the new estimate to be the current estimate minus the Number using Newtons formula\n",
    "        x -= ((x*x)- S)/ (2 * x)\n",
    "        # or equivalently the babylonian guess and divide formula\n",
    "        #x= (x + S/x)/2\n",
    "   \n",
    "    \n",
    "    print(x)\n",
    "    return x\n",
    "   \n",
    "sqrtn()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.414213562373095e+100\n"
     ]
    }
   ],
   "source": [
    "# define the function\n",
    "def sqrt2():\n",
    "    \n",
    "    S = 2 * 10**200\n",
    "    # first estimate\n",
    "    x = S\n",
    "    # repeat until there is no difference between the squared estimate gives the square back\n",
    "    # while abs(x*x -S) > 0.000000000001:\n",
    "    while abs(x*x -S) > 0:\n",
    "        # update the new estimate to be the mean of the current estimate and the number divided by the estimate\n",
    "        \n",
    "        x= (x + S/x)/2\n",
    "        \n",
    "        #x -= ((x*x)- S)/ (2 * x) # this gives 1 extra digit\n",
    "    return x\n",
    "        \n",
    "    \n",
    "print(sqrt2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.414213562373095027142412563281858698349164881791987548177900388860130684271654303022821004349852877e+100'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string formatting to get 100 significant digits\n",
    "format(sqrtn(),'.100g')\n",
    "format(sqrt2(),'.100g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.414213562373095e+100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.414213562373095027142412563281858698349164881791987548177900388860130684271654303022821004349852877e+100'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math_root2 = math.sqrt(2*(10**200))\n",
    "print(math_root2)\n",
    "format(math_root2,'.100g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.414213562373095e+100\n",
      "1.414213562373095e+100\n",
      "The square root of two using my function sqrt2() is \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the function\n",
    "def sqrt2():\n",
    "\n",
    "    sqrt_string =\"\"\n",
    "    S = 2 # This is the number we want to get the square root of\n",
    "    \n",
    "    S = S*(10**200) # 2 by 10 to power of 200\n",
    "\n",
    "    x = S\n",
    "   \n",
    "    # while the difference between the number and the square of the guess is greater than 0\n",
    "    while abs(S -(x *x)) > 0.000000000000001:\n",
    "        x= (x + S/x)/2\n",
    "    \n",
    "    str_x = str(x)\n",
    "    \n",
    "    for s in str_x:\n",
    "        sqrt_string += s\n",
    "    \n",
    "    print(sqrt_string)\n",
    "    \n",
    "\n",
    "\n",
    "sqrt2()\n",
    "\n",
    "print(f\"The square root of two using my function sqrt2() is \\n{sqrt2()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A further bit of research found this post from [geeksforgeeks.com](https://www.geeksforgeeks.org/square-root-of-an-integer/?ref=rp) which uses a binary search function to find the largest integer *i* whose square is less than or equal to the original number. The values of i * i is monotonically increasing, so the problem can be solved using binary search.\n",
    " \n",
    "The code there uses integer division and defines the lower and upper bounds, the midpoint and the answer at each iteration. The loop runs until the lower bound is less than or equal to the upper bound. Then it checks if the midpoint squared is equal to the number and narrows the search to one half of the search space. \n",
    "\n",
    "If I apply this function below to get the square root of two it returns 1 as it uses integer division. However if I apply it to a very large multiple of two as outlined earlier, the digits do actually match those from Wikipedia for the square root of two. The task however is not to get the square root of 2e200 to 100 decimal places but to get the square root of two so I attempt to do some string manipulation and convert the digits into a string representing the square root of two. \n",
    "\n",
    "(~~When I do perform the conversion from the integer into a string with the decimal point in the right place (for the square root of 2) I actually get the same result as from my own function. This might indicate that my original solution might actually be producing the correct answer after all. Integer division did not work with my earlier code but using lower and upper bounds might reduce the number of iterations required and prevent it from crashing.~~)\n",
    "\n",
    "The code below adapts the binary search code to calculate the square root of 2e200. It then convert the result into a string and performs some string manipulation by first creating an empty string, then iterating through each digit of the string result, extracting each of the digits after the first one and concatenating them to the string \"1.\" This does recreate the first 100 digits of the square root of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 100 digits of the square root of 2 are \n",
      "1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapted and extended from code on geekforgeeks contributed by Nikita Tiwari. \n",
    "  \n",
    "# Returns floor of square root of x          \n",
    "def sqrt2() : \n",
    "   \n",
    "    # set up an empty string to hold the result\n",
    "    sqrt_string =\"\"\n",
    "    \n",
    "    S = 2 * 10**200\n",
    "    # Base cases is only required for the general case\n",
    "    if (S == 0 or S == 1) : \n",
    "        return S \n",
    "   \n",
    "    # Do Binary Search to find the square root of S \n",
    "    lower = 1\n",
    "    upper = S    \n",
    "    while (lower <= upper) : \n",
    "        x = (lower + upper) // 2\n",
    "          \n",
    "        # If x squared is a perfect square then return x\n",
    "        if (x*x==S) : \n",
    "            return x \n",
    "              \n",
    "        # As we need the floor, update the answer when mid*mid is smaller than x, and move closer to getting the square root of S\n",
    "        if (x*x < S) : \n",
    "            lower = x + 1\n",
    "            ans = x \n",
    "              \n",
    "        else : \n",
    "              \n",
    "            # If mid*mid is greater than x \n",
    "            upper = x-1\n",
    "                          \n",
    "    #return ans \n",
    "\n",
    "    # create a string version of the result\n",
    "    str_ans = str(ans)\n",
    "    \n",
    "    for s in str_ans:\n",
    "        sqrt_string += s\n",
    "      \n",
    "    # concatenate the strings to produce the square root of 2\n",
    "    sqrt_string = \"1.\"  + sqrt_string[1:]\n",
    "    #print(f\"The square root of 2 to 100 decimal places is \\n{sqrt_string}\")\n",
    "      \n",
    "    # this will return an integer for square root of 2e200\n",
    "    #return ans   \n",
    "    \n",
    "    # instead return the string containing the first 100 digits of square root of 2 \n",
    "    print(f\"The first 100 digits of the square root of 2 are \\n{sqrt_string}\")\n",
    "    return sqrt_string\n",
    "    \n",
    "    \n",
    "\n",
    "# call the function to print the first 100 digits of the square root of 2\n",
    "sqrt2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post [10,000 digits of Square Root of 2](https://nerdparadise.com/math/reference/2sqrt10000) on nerdparadise.com has the digits of the square root of 2 to 10,1000 places:\n",
    "1.\n",
    "4142135623 7309504880 1688724209 6980785696 7187537694 8073176679 7379907324 7846210703 8850387534 3276415727 \n",
    "\n",
    "These are the results of the function above:\n",
    "\n",
    "14142135623 7309504880 1688724209 6980785696 7187537694 8073176679 7379907324 7846210703 8850387534 3276415727\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some notes on the Square root of 2 task.\n",
    "\n",
    "- The final function above does yield the correct digits for the square root of 2. It is a string however and further numerical calculations cannot be performed on the string. Converting from one type to another will not always return results as expected. \n",
    "- My original function using the babylonian guess and divide method does return the exact same result as  `math.sqrt` to 15 decimal places. \n",
    "\n",
    "- This task illustrates the problems with accuracy to high levels of precision and how when converting between types you won't always get what you expect. The lecture on data types and numbers highlighted that there are some irrational numbers that simply cannot be stored on a computer. Procedures can be written to produce the value when needed though. The article from the Python tutorial on the problems with floating point numbers showed an example of how there are many different decimal numbers which actually share the same nearest approximate binary fraction. It demonstrated how the numbers 0.1 and 0.10000000000000001 and 0.1000000000000000055511151231257827021181583404541015625 are all approximated by 3602879701896397 / 2 ** 55.\n",
    "\n",
    "In reality, while we would be concerned with the accuracy of results, other considerations would be the computational cost and time.  When I tried to run some versions of my code, my computer struggled!  Newton's method uses approximations and while it converges towards the actual result, the number of steps to reach this is infinite. This is combined with the problems outlined earlier of computing and storing real numbers on a computer.\n",
    "The post on [Square Roots via Newton’s Method](https://math.mit.edu/~stevenj/18.335/newton-sqrt.pdf) on MIT course 18.335 implements the square root of 2 using the Julia language. It notes that we need to be concerned with the time and computational resources required in addition to the accuracy of the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References. I will fix these up and place them at the bottom of the notebook.\n",
    "Task 1\n",
    "- [1][Wikipedia](https://en.wikipedia.org/wiki/Square_root)\n",
    "- [2][Wikipedia](https://en.wikipedia.org/wiki/Square_root_of_2)\n",
    "- [3][geeksforgeeks](https://www.geeksforgeeks.org/square-root-of-2/)\n",
    "- [4][mathsisfun](https://www.mathsisfun.com/numbers/square-root-2-irrational.html)\n",
    "- [5][The Maths Book: Big Ideas Simply explained](published by Dorling Kindersley Limited)\n",
    "- [6] Lecture Notes from Machine Learning and Statistics, Lecturer Dr. Ian McLoughlin\n",
    "The lecture on data types of this module looked at the binary representation of integers and floats.\n",
    "- [7][Floating Point Arithmetic: Issues and Limitations](https://docs.python.org/3/tutorial/floatingpoint.html) \n",
    "- [8][IEEE 754](https://en.wikipedia.org/wiki/IEEE_754) \n",
    "- [9][IEEE Standard 754 Floating Point Numbers](https://www.geeksforgeeks.org/ieee-standard-754-floating-point-numbers/) article on <geeksforgeeks.com>.\n",
    "- [10][The Perils of Floating Point](http://www.lahey.com/float.htm)\n",
    "- [11][str.format](https://docs.python.org/3/library/stdtypes.html#str.format)\n",
    "- [12][Python `math` module](https://docs.python.org/3/library/math.html?highlight=math#module-math)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 2 \n",
    "The Chi-squared test for independence is a statistical hypothesis test like a t-test. It is used to analyse whether two categorical variables are independent. The Wikipedia article gives the table below as an example [4], stating the Chi-squared value based on it is approximately 24.6. Use scipy.stats to verify this value and calculate the associated p value. You should include a short note with references justifying your analysis in a markdown cell.\n",
    "\n",
    "|   | A | B | C | D | Total|\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|White Collar|90 | 60 | 104 | 95 | 349 |\n",
    "|Blue Collar |30 |50 |51|20|151\n",
    "|No Collar |30 |40|45|35|150\n",
    "|Total|150 |150|200|150 |650|\n",
    "\n",
    "- [https://en.wikipedia.org/w/index.php?title=Chi-squaredtest&oldid=983024096](https://en.wikipedia.org/w/index.php?title=Chi-squaredtest&oldid=983024096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract from Wikipedia Article in question:\n",
    "Here is an extract from the article in question on the [Chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test) on Wikipedia from which the above table is taken. \n",
    "\n",
    ">A chi-squared test, also written as $\\chi^2$ test, is a statistical hypothesis test that is valid to perform when the test statistic is chi-squared distributed under the null hypothesis, specifically Pearson's chi-squared test and variants thereof. Pearson's chi-squared test is used to determine whether there is a statistically significant difference between the expected frequencies and the observed frequencies in one or more categories of a contingency table.\n",
    "In the standard applications of this test, the observations are classified into mutually exclusive classes. If the null hypothesis that there are no differences between the classes in the population is true, the test statistic computed from the observations follows a $\\chi^2$ frequency distribution. The purpose of the test is to evaluate how likely the observed frequencies would be assuming the null hypothesis is true.\n",
    "Test statistics that follow a $\\chi^2$ distribution occur when the observations are independent and normally distributed, which assumptions are often justified under the central limit theorem. There are also $\\chi^2$ tests for testing the null hypothesis of independence of a pair of random variables based on observations of the pairs.\n",
    "Chi-squared tests often refers to tests for which the distribution of the test statistic approaches the $\\chi^2$ distribution asymptotically, meaning that the sampling distribution (if the null hypothesis is true) of the test statistic approximates a chi-squared distribution more and more closely as sample sizes increase.\n",
    "\n",
    "##### Example chi-squared test for categorical data (extract from same Wikipedia article as above)\n",
    ">Suppose there is a city of 1,000,000 residents with four neighborhoods: A, B, C, and D. A random sample of 650 residents of the city is taken and their occupation is recorded as \"white collar\", \"blue collar\", or \"no collar\". The null hypothesis is that each person's neighborhood of residence is independent of the person's occupational classification. The data are tabulated as:\n",
    "Let us take the sample living in neighborhood A, 150, to estimate what proportion of the whole 1,000,000 live in neighborhood A. Similarly we take $\\frac{349}{650}$ to estimate what proportion of the 1,000,000 are white-collar workers. By the assumption of independence under the hypothesis we should \"expect\" the number of white-collar workers in neighborhood A to be:\n",
    "$$150 x \\frac{349}{650}\\approx80.54$$\n",
    "Then in that \"cell\" of the table, we have $\\frac{(observed-expected)^2}{expected}$ = $\\frac{(90-80.54)^2}{80.54}\\approx1.11$.\n",
    "The sum of these quantities over all of the cells is the test statistic; in this case, $\\approx24.6$. Under the null hypothesis, this sum has approximately a chi-squared distribution whose number of degrees of freedom are $\\text{number of rows}-1)({\\text{number of columns}}-1)=(3-1)(4-1)=6$\n",
    "If the test statistic is improbably large according to that chi-squared distribution, then one rejects the null hypothesis of independence.\n",
    "\n",
    ">A related issue is a test of homogeneity. Suppose that instead of giving every resident of each of the four neighborhoods an equal chance of inclusion in the sample, we decide in advance how many residents of each neighborhood to include. Then each resident has the same chance of being chosen as do all residents of the same neighborhood, but residents of different neighborhoods would have different probabilities of being chosen if the four sample sizes are not proportional to the populations of the four neighborhoods. In such a case, we would be testing \"homogeneity\" rather than \"independence\". The question is whether the proportions of blue-collar, white-collar, and no-collar workers in the four neighborhoods are the same. However, the test is done in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notes on the Chi-Squared test\n",
    "(based on the above article, some previous college notes, and other sources referenced.)\n",
    "\n",
    "- The Chi-Squared test is used to analyse whether two categorical variables are independent.\n",
    "Categorical data is data where each observation belongs to one of a set of categories. There are 2 types of categorical data:\n",
    "    1. Nominal data has two or more categories but there is no ordering of the categories such as Gender - male / female\n",
    "    2. Ordinal where there is a clear ordering of the variables such as education levels (primary, secondary, tertiary)\n",
    "Categorical data is often referred to as count data because the number of observations belonging to a particular category are counted.\n",
    "- If only one categorical variable is measured on each member of the sample, then the data are considered univariate or one-dimensional. \n",
    "- If two variables are measured the data are bivariate.\n",
    "With a sample from a single population, the data are best summarised in a one-way-frequency table (frequency distribution) which lists the possible categories and the number of sample values belonging to each (frequency).\n",
    "Begin by summarising the sample data in a one-way frequency table with k cells (k is the number of categories). The frequencies are often referred to as cell counts. The hypotheses to be tested concern the probabilities p1, p2, ..., pk which are often proportions of a population falling into each category.\n",
    "\n",
    "\n",
    "- A $\\chi^2$ test is used to determine if there is a statistically significant difference between the expected frquencies and the observed frequencies in one or more categories of a contingency table.\n",
    "- In the standard applications of this test, the observations are classified into mutually exclusive classes.\n",
    " \n",
    "- If the null hypothesis that there are no differences between the classes in the population is true, the test statistic computed from the observations follows a $\\chi^2$ frequency distribution. \n",
    "- The purpose of the test is to evaluate how likely the observed frequencies would be assuming the null hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the table data.\n",
    "\n",
    "- The city has a population of 1,000,000 residents with four neighbourhoods, A, B ,C and D.\n",
    "- A random sample of 650 residents is taken. \n",
    "- The occupation of the 650 sampled residents is recorded as \"white collar\", \"blue collar\" or \"no collar\".\n",
    "\n",
    "To see if the proportions of residents living in the neighbourhoods (belonging to the categories) 'A', 'B','C' and 'D' are the same for the occupational categories of White Collar, Blue Collar and No Collar, a sample is taken and one-way frequency tables are constructed for each category. Two or more one-way frequency tables can be combined to get a two-way frequency table which is also known as a contingency table.\n",
    "\n",
    "The table here is a two-way frequency table.\n",
    "\n",
    "|   | A | B | C | D | Total|\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|White Collar|90 | 60 | 104 | 95 | 349 |\n",
    "|Blue Collar |30 |50 |51|20|151\n",
    "|No Collar |30 |40|45|35|150\n",
    "|Total|150 |150|200|150 |650|\n",
    "\n",
    "- The cell counts are the numbers in a particular sample that belong to a particular category.\n",
    "- The column and row totals are known as the marginal totals and each set of marginal totals adds to the grand total. \n",
    "- In this case the row totals are the sizes of the samples selected from the different occuational populations (i.e. white-collar, blue-collar, no-collar).\n",
    "- The column totals are the sizes of the samples selected from the different neighbour populations A, B, C and D.\n",
    "- The null hypothesis is that each person's neighbourhood of residence is independent of the person's occupational classification.\n",
    "\n",
    "\n",
    "- 150 of the sample live in neighbourhood A. This figure can be used to estimate what proportion of the 1 million residents live in neighbourhood A. \n",
    "- 150 of the sample live in neighbourhood B. This figure can be used to estimate what proportion of the 1 million residents live in neighbourhood B.\n",
    "- 200 of the sample live in neighbourhood C. This figure can be used to estimate what proportion of the 1 million residents live in neighbourhood C.\n",
    "- 95 of the sample live in neighbourhood D. This figure can be used to estimate what proportion of the 1 million residents live in neighbourhood D.\n",
    "\n",
    "\n",
    "- In the same way, 349 of the sample are white-collar workers. This figure can be used to determine what proportion if the 1 million residents are white-collar workers.\n",
    "\n",
    "- 151 of the sample are blue-collar workers. This figure can be used to determine what proportion if the 1 million residents are blue-collar workers.\n",
    "- 150 of the sample are no-collar workers. This figure can be used to determine what proportion if the 1 million residents are no-collar workers.\n",
    "\n",
    "- Under the null hypothesis (that each person's neighbourhood of residence is independent of the person's occupational classification) we would expect the number of white collar workers in the neightbourhood *A* to be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### One-way frequency table\n",
    "The first row of the table for white collar workers in the sample is a one-way frequency table with $k$ = 4 categories for a sample of 349.\n",
    "\n",
    "|Observed Cell Counts| A | B | C | D | Total|\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|White Collar|90 | 60 | 104 | 95 | 349 |\n",
    "\n",
    "A question here could be does the data indicate a preference for white collar residents to prefer a particular neighbourhood? If a white-collar worker has no preference for a particular neighbourhood then the proportion of the population in each of the four neighbourhoods would be $\\frac{1}{4}$. The hypothesis would be $H_0: p_1 = p_2 = p_3 = p_4 = \\frac{1}{4}$ vs $H_A: H_0: \\text{not true}$ (or at least one proportion is not $\\frac{1}{4}$ ).\n",
    "\n",
    "The null hypothesis is that the white collar workers have no preference for a particular neighbourhood (i.e. the proportions for each of the categories are equal) and the alternative hypothesis is that the null is not true (i.e. the proportions for each of the categories are not the same). To test the hypotheses you need to calculate the frequencies (cell counts) that would be expected if the null hypothesis was true, ie if the white-collar workers had no preference for a particular neighbourhood. These expected cell counts are $np_1$, $np_2$ etc.\n",
    "\n",
    "\n",
    "The table above shows the observed counts from the experiment.\n",
    "If the null hypothesis was true, that the white-collar workers have no neighbourhood preference, we would expect to see the following:\n",
    "\n",
    "|ExpectedCell Counts| A | B | C | D | Total|\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|White Collar|87.25| 87.25 | 87.25 | 87.25 | 349 |\n",
    "\n",
    "    - $np_1$ = 349 * 0.25\n",
    "    - $np_2$ = 349 * 0.25\n",
    "    - $np_3$ = 349 * 0.25\n",
    "    - $np_4$ = 349 * 0.25\n",
    "\n",
    "The next step is to compare the observed and the expected cell counts. \n",
    "If the differences between them are so big that they could not be explained by sampling variation then we reject the null hypothesis in favour of the alternative hypothesis. The comparison of observed and expected cell counts is made by calculating:\n",
    "\n",
    "\n",
    "$$\\frac{(Observed Count - Expected Count)^2}{Expected Count}$$ for each cell and then adding the values for all cells to get the chi-square test statistics.\n",
    "\n",
    "$$\\chi^2=\\sum_{i=1}^{k}\\frac{(O_i-E_i)^2}{E_i}$$\n",
    "\n",
    "- Large values of $\\chi^2$ suggest rejection of the Null hypothesis in favour of the alternative hypothesis. \n",
    "- Small values of $\\chi^2$ would support the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 349, Proportion A: 0.25787965616045844, Proportion B: 0.17191977077363896,Proportion C: 0.2979942693409742, Proportion D: 0.2722063037249284\n",
      "Total 349, \n",
      "Expected A: 87.25\n",
      "Expected B: 87.25\n",
      "Expected C: 87.25\n",
      "Expected D: 87.25\n",
      " \n"
     ]
    }
   ],
   "source": [
    "A, B, C, D =90, 60, 104,95\n",
    "\n",
    "Total = A+B+C+D\n",
    "# Actual observed proportions\n",
    "print(f\"Total: {Total}, Proportion A: {A/Total}, Proportion B: {B/Total},Proportion C: {C/Total}, Proportion D: {D/Total}\")\n",
    "# Expected Proportions under the null hypothesis\n",
    "print(f\"Total {Total}, \\nExpected A: {Total *0.25}\\nExpected B: {Total *0.25}\\nExpected C: {Total *0.25}\\nExpected D: {Total *0.25}\\n \")\n",
    "#print(f\"Total: {Total}, Proportion White Collar: {White/Total}, Proportion Blue Collar: {Blue/Total},Proportion No Collar: {No/Total}, Proportion D: {D/Total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|   | A | B | C | D | Total|\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|White Collar|90 | 60 | 104 | 95 | 349 |\n",
    "|Blue Collar |30 |50 |51|20|151\n",
    "|No Collar |30 |40|45|35|150\n",
    "|Total|150 |150|200|150 |650|\n",
    "\n",
    "The null hypothesis is that each person's neighborhood of residence is independent of the person's occupational classification.\n",
    "This would mean that the two variables neighbourhood and occupational classification are independent. Knowing a person's occupational classification does not tell you anything about where they live.\n",
    "This considers whether the proportion of workers living  in the neighbourhoods \"A\", \"B\",\"C\" and \"D\" (belonging to the categories) are the same for the person's classification as White-Collar, Blue-Collar or No-Collar. \n",
    "\n",
    "Select a sample and construct a one-way frequency table for each classification.\n",
    "\n",
    "The table provided in Wikipedia is a two-way frequency table. It is comparing more than two populations. \n",
    "\n",
    "To see if the proportions of persons belonging to the categories 'A', 'B', C' and 'large' are the same for the occupational classifications of White-collar, Blue-collar and No-Collar, a sample is selected and a one-way select one-way frequency table is constructed for each occupational category. \n",
    "A two-way table, also known as a contingency table, is the result of combining two or more one-way frequency tables.\n",
    "The cell counts are the numbers in a particular sample that belong to a particular category. The column and row totals are known as the marginal totals and each set of marginal totals adds to the grand total. In this case the row totals are the sizes of the samples selected from the different populations (i.e. occupational classification of residents).\n",
    "The Null Hypothesis would be that the neighbourhood category proportions are the same for all occupational classifications\n",
    "- $H_0$ : Neighbourhood category proportions are the same for all classifications of occupations.\n",
    "- $H_A: H_0$ is not true.\n",
    "Assume the null hypothesis is true, The Expected cell counts = (row total times the column total) / grand total)\n",
    "Assuming the null hypothesis to be true $\\chi^2$ is approximately chi-squared distributed with df = (Number of rows- 1).(Number of columns - 1). In this case the degrees of freedom (3-1 x 4-1) is 6. If calculated manually the test statistic would be compared to the critical value (from a table such as the New Cambridge Statistical Tables) at a particular alpha level such as 0.05 taking into account the degrees of freedom. \n",
    "\n",
    "- If the chi-squared test statistic is less than the chi-squared critical value with 6 degrees of freedom (at the chosen alpha level such as 0.05) then you would fail to reject the null hypothesis.\n",
    "- If the chi-squared test statistic is greater than the chi-squared critical value, then the null hypothesis would be rejected and you would accept the alternative hypothesis that the data contains sufficient evidence of neighbourhood preference by occupational classification. The proportions of residents in the four neighbourhoods A, B, C and D are not the same for the 3 occupational classifications of white-collar, blue-collar and no-collar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proportions of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 650, Proportion A: 0.23076923076923078, Proportion B: 0.23076923076923078,Proportion C: 0.3076923076923077, Proportion D: 0.23076923076923078\n",
      "Total: 650, Proportion White Collar: 0.536923076923077, Proportion Blue Collar: 0.2323076923076923,Proportion No Collar: 0.23076923076923078, Proportion D: 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "A, B, C, D =150, 150, 200,150\n",
    "White, Blue, No = 349,151,150\n",
    "Total = A+B+C+D\n",
    "print(f\"Total: {Total}, Proportion A: {A/Total}, Proportion B: {B/Total},Proportion C: {C/Total}, Proportion D: {D/Total}\")\n",
    "print(f\"Total: {Total}, Proportion White Collar: {White/Total}, Proportion Blue Collar: {Blue/Total},Proportion No Collar: {No/Total}, Proportion D: {D/Total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the assumption of independence under the hypothesus\n",
    "\n",
    "- $H_0$ : Category proportions are the same for all categories\n",
    "- $H_A: H_0$ is not true.\n",
    "- Assume the null hypothesis is true, The Expected cell counts = (row total times the column total) / grand total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will put the data from the contingency table into a pandas dataframe and then create an expected frequency table based on the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White_collar</th>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_collar</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No-Collar</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A    B    C    D  Total\n",
       "White_collar   90   60  104   95    349\n",
       "Blue_collar    30   50   51   20    151\n",
       "No-Collar      30   40   45   35    150\n",
       "Total         150  150  200  150    650"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas dataframe\n",
    "df=pd.DataFrame({\"A\":[90,30,30], \"B\":[60,50,40],\"C\":[104,51,45],\"D\":[95,20,35]})\n",
    "df.index = ['White_collar', 'Blue_collar', 'No-Collar'] \n",
    "# add a total column to sum across each row\n",
    "df[\"Total\"] = df.sum(axis=1)\n",
    "# add a row to sum across column totals \n",
    "#(https://stackoverflow.com/questions/20804673/appending-column-totals-to-a-pandas-dataframe)\n",
    "df.loc['Total']= df.sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The column and row totals are known as the **marginal totals**\n",
    "- Each set of marginal totals adds to the **grand Total**\n",
    "- in this case the row totals are the sizes of the samples from the different populations (occupational classification)\n",
    "- Ho : Category proportions in the different neightbourhoods are the same for all occupational classifications \n",
    "- HA: H0 not true.\n",
    "Assume the null hypothesis is true,\n",
    "The expected cell counts = $\\frac{\\text{row total} \\times \\text{column total}}{Grand Total}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n"
     ]
    }
   ],
   "source": [
    "# get the marginal row totals\n",
    "WhiteCollarTotal =df.iat[0, 4] \n",
    "BlueCollarTotal=df.iat[1,4]\n",
    "NoCollarTotal=df.iat[2,4]\n",
    "# get the marginal column total\n",
    "ATotal=df.iat[3,0]\n",
    "BTotal=df.iat[3,1]\n",
    "CTotal=df.iat[3,2]\n",
    "DTotal=df.iat[3,3]\n",
    "# get the grand total\n",
    "GrandTotal = df.iat[3,4]\n",
    "\n",
    "print(GrandTotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe representing the expected frequencies. The marginal row and column totals as well as the overall grand total are the same as totals for the observed frequencies tables.\n",
    "Note some rounding is introduced here.\n",
    "Then calculate the chi-squared test statistic. \n",
    "Note this is just for some background on the table and to verify the results from the scipy-stats package which has a functions that will actually do all of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White_collar</th>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>107</td>\n",
       "      <td>81</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_collar</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No-Collar</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>199</td>\n",
       "      <td>151</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A    B    C    D  Total\n",
       "White_collar   81   81  107   81    350\n",
       "Blue_collar    35   35   46   35    151\n",
       "No-Collar      35   35   46   35    151\n",
       "Total         151  151  199  151    652"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas dataframe using dictionaries containing zero values to start\n",
    "dfE =pd.DataFrame({\"A\":[0,0,0], \"B\":[0,0,0],\"C\":[0,0,0],\"D\":[0,0,0]})\n",
    "# add an index\n",
    "dfE.index = ['White_collar', 'Blue_collar', 'No-Collar'] \n",
    "\n",
    "# Calculate the White collar expected frequencies\n",
    "dfE.iat[0,0]=round((WhiteCollarTotal*ATotal)/GrandTotal)\n",
    "dfE.iat[0,1]=round((WhiteCollarTotal*BTotal)/GrandTotal)\n",
    "dfE.iat[0,2]=round((WhiteCollarTotal*CTotal)/GrandTotal)\n",
    "dfE.iat[0,3]=round((WhiteCollarTotal*DTotal)/GrandTotal)\n",
    "# Blue collar\n",
    "dfE.iat[1,0]=round((BlueCollarTotal*ATotal)/GrandTotal)\n",
    "dfE.iat[1,1]=round((BlueCollarTotal*BTotal)/GrandTotal)\n",
    "dfE.iat[1,2]=round((BlueCollarTotal*CTotal)/GrandTotal)\n",
    "dfE.iat[1,3]=round((BlueCollarTotal*DTotal)/GrandTotal)\n",
    "# No Collar\n",
    "dfE.iat[2,0]=round((NoCollarTotal*ATotal)/GrandTotal)\n",
    "dfE.iat[2,1]=round((NoCollarTotal*BTotal)/GrandTotal)\n",
    "dfE.iat[2,2]=round((NoCollarTotal*CTotal)/GrandTotal)\n",
    "dfE.iat[2,3]=round((NoCollarTotal*DTotal)/GrandTotal)\n",
    "\n",
    "# add a total column to sum across each row\n",
    "dfE[\"Total\"] = dfE.sum(axis=1)\n",
    "# add a row to sum across column totals \n",
    "dfE.loc['Total']= dfE.sum()\n",
    "dfE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White_collar</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.444444</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>2.419753</td>\n",
       "      <td>8.951167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_collar</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>14.114907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No-Collar</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.456933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>2.435194</td>\n",
       "      <td>12.593924</td>\n",
       "      <td>0.654355</td>\n",
       "      <td>8.854947</td>\n",
       "      <td>24.554034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A          B         C         D      Total\n",
       "White_collar  1.000000   5.444444  0.084112  2.419753   8.951167\n",
       "Blue_collar   0.714286   6.428571  0.543478  6.428571  14.114907\n",
       "No-Collar     0.714286   0.714286  0.021739  0.000000   1.456933\n",
       "Total         2.435194  12.593924  0.654355  8.854947  24.554034"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the chi-squared statistic using the formula\n",
    "chi = ((df-dfE)**2)/dfE\n",
    "chi\n",
    "chi[\"Total\"] = chi.sum(axis=1)\n",
    "\n",
    "chi.loc['Total']= chi.sum()\n",
    "chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to do some rounding here but the value is close to the Chi-squared value in the Wikipedia article.\n",
    "The next step is to use the `scipy.stats` to verify this value and calculate the associated p value. \n",
    "Include a short note with references justifying your analysis in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|   | A | B | C | D | Total|\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|White Collar|90 | 60 | 104 | 95 | 349 |\n",
    "|Blue Collar |30 |50 |51|20|151\n",
    "|No Collar |30 |40|45|35|150\n",
    "|Total|150 |150|200|150 |650|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy.stats functions for Chi-Squared tests\n",
    "\n",
    "- [Scipy stats - Statistical Tests](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests)\n",
    "\n",
    "- `scipy.stats.chisquare(f_obs, f_exp=None, ddof=0, axis=0)`\n",
    "- [Calculate a one-way chi-square test.](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html#scipy.stats.chisquare)\n",
    "The chi-square test tests the null hypothesis that the categorical data has the given frequencies.\n",
    "- The function takes as parameters an array of observed frequencies in each category, an array of expected frequencies in each category and the degrees of freedom. By default the categories are assumed to be equally likely.\n",
    "The expected frequencies for the table from Wikipedia are not provided in the article but can be calculated.\n",
    "\n",
    "The [Scipy.stats.chi2_contingnency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html#scipy.stats.chi2_contingency) function computes the chi-square statistic and p-value for the hypothesis test of independence of the observed frequencies in the *observed* contingency table.  The expected frequencies are computed based on the marginal sums under the assumption of independence. The [scipy.stats.contingency.expected_freq(observed)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.contingency.expected_freq.html#scipy.stats.contingency.expected_freq) function can be used to compute the expected frequencies from a contingency table.\n",
    "Given an n-dimensional contingency table of observed frequencies, compute the expected frequencies for the table based on the marginal sums under the assumption that the groups associated with each dimension are independent.\n",
    "The parameters this function takes is an array of observed values. The function returns an array of expected frequencies, based on the marginal sums of the table. The expected values returned will be of type `float`. The shape of the expected values will be the same as the observed.\n",
    "So for example, our table has 3 rows and 4 columns of observed values. Therefore the array of expected values will be the same. The expected values are calculated in the same way as I showed above behind the scenes using marginal sums of the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90,  60, 104,  95],\n",
       "       [ 30,  50,  51,  20],\n",
       "       [ 30,  40,  45,  35]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observed is the multidimensional arrays of values from the original table. \n",
    "observed = np.array([[90,60,104,95],[30,50,51,20],[30,40,45,35]])\n",
    "observed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating expected frequencies  using Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 80.53846154,  80.53846154, 107.38461538,  80.53846154],\n",
       "       [ 34.84615385,  34.84615385,  46.46153846,  34.84615385],\n",
       "       [ 34.61538462,  34.61538462,  46.15384615,  34.61538462]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.contingency import expected_freq\n",
    "expected_freq(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) is used to calculate the Chi-square test of independence of variables in a contingency table and can be applied to the table of data here.\n",
    "\n",
    "This function computes the chi-square statistic and p-value for the hypothesis test of independence of the observed frequencies in the contingency table observed. The number of degrees of freedom is (expressed using numpy functions and attributes).\n",
    "The function takes as parameters the contingency table which contains the observed frequencies  or number of occurences in each category. (In the two-dimensional case, the table is often described as an “R x C table”.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html#scipy.stats.chi2_contingency)\n",
    "- `scipy.stats.chi2_contingency(observed, correction=True, lambda_=None)`\n",
    "\n",
    "Chi-square test of independence of variables  on a contingency table.\n",
    "\n",
    "\n",
    "|   | A | B | C | D | Total|\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|White Collar|90 | 60 | 104 | 95 | 349 |\n",
    "|Blue Collar |30 |50 |51|20|151\n",
    "|No Collar |30 |40|45|35|150\n",
    "|Total|150 |150|200|150 |650|\n",
    "\n",
    "The chi-squared test statistic is a test for the independence of different categories of a population. It should only be used when the dimension of observed is two or more. \n",
    "\n",
    "This function computes a chi-square statistic. It computes the expected frequencies and the degrees of freedom from the given contingency table. (The degrees of freedom is calculated as follows:\n",
    "`dof = observed.size - sum(observed.shape) + observed.ndim - 1`).\n",
    "\n",
    "The function returns the chi-squared test statistic as a float, the p-value of the test (also a float), the degrees of freedom (an integer) and the expected frequencies based on the marginal sum of the table of observed frequencies (an ndarray of the same shape as the table of observed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dof = observed.size - sum(observed.shape) + observed.ndim - 1\n",
    "dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90,  60, 104,  95],\n",
       "       [ 30,  50,  51,  20],\n",
       "       [ 30,  40,  45,  35]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import from scipy.stats\n",
    "from scipy.stats import chi2_contingency\n",
    "# The array of observed frequencies\n",
    "obs = np.array([[90,60,104,95], [30,50,51,20],[30,40,45,35]])\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.5712028585826,\n",
       " 0.0004098425861096696,\n",
       " 6,\n",
       " array([[ 80.53846154,  80.53846154, 107.38461538,  80.53846154],\n",
       "        [ 34.84615385,  34.84615385,  46.46153846,  34.84615385],\n",
       "        [ 34.61538462,  34.61538462,  46.15384615,  34.61538462]]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_contingency(obs)\n",
    "#print(f\"The chi-squared statistic calculated using the scipy stats package is {chi2_contingency(obs)[0]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chi-squared statistic calculated using the scipy stats package is 24.5712028585826 \n",
      "The p-value is 0.0004098425861096696 \n"
     ]
    }
   ],
   "source": [
    "print(f\"The chi-squared statistic calculated using the scipy stats package is {chi2_contingency(obs)[0]} \")\n",
    "print(f\"The p-value is {chi2_contingency(obs)[1]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi-squared value is compared to the chi-squared critical value which takes into account the alpha level of significance and the degrees of freedom. If the chi-squared test statistic is greater than the critical value of chi at that alpha level for the number of degrees of freedom, then the null hypothesis of independence is rejected and we can conclude that the data contains sufficient evidence of neighbourhood preference by occupational categories.\n",
    "The p-value is calculated here using a significance level of 0.05 for the hypothesis test. The calculated p-value is 0.0004098425861096696 and this is less than the alpha level of 0.05 which means that the null hypothesis should be rejected in favour of the alternative hypothesis. We can conclude that the data supports the hypothesis that the choice of neighbourhood is not independent of occupational classification. The categorical variables in this data are not independent.\n",
    "When the observed and expected cell counts are compared, if the differences between them are too big to be explained by sampling variation then the null hypothesis is rejected in favour of the alternative hypothesis. Large values of the chi-squared suggest rejection of the null hypothesis in favour of the alternative hypothesis. The overall difference between what was observed and what would have been expected under the nul hypothesis is larger. Smaller values of chi-squared test stat are compatible with the null hypothesis. The null hypothesis is rejected if the chi-squared test statistic is greater than some critical value. The critical value is chosen in such as way that the probability of a type 1 error is equal to alpha. To do this you need to know the sampling distribution of chi-squared when the null hypothesis is true. The distribution is approximately a chi-squared distribution with k-1 degrees of freedom. The conditions of Chi-squared is that the  approximation is good  when every expected cell count is greater than or equal to 5, and the n observed counts are a random sample from the population of interest.\n",
    "The critical value for a chi-squared test can be looked up in Table 8 of the New Cambridge Statistical tables. You need the alpha level and the degrees of freedom.\n",
    "For this example, alpha = 0.05 and degrees of freedom = k-1 = 6. The chi-squared critical value from page 41 of the tables is 12.59. I will look this up online also. Since the chi-squared test statistic is greater than the critical value we can reject the null hypothesis and conclude that the data contains sufficient evidence of neighbourhood preference by occupational classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi-squared statistic calculated here by scipy is the same as I manually calculated above and also the same as reported in the Wikipedia article referred to in the task description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References for Task 2\n",
    "\n",
    "\n",
    "- Wikipedia contributors, “Chi-squared test — Wikipedia, the free encyclopedia,” 2020, [Online; accessed 1-November-2020][Online]. Available: https://en.wikipedia. org/w/index.php?title=Chi-squared test&oldid=983024096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 3\n",
    "November 16th, 2020: The standard deviation of an array of numbers x is calculated using numpy as `np.sqrt(np.sum((x - np.mean(x))**2)/len(x))` . However, Microsoft Excel has two different versions of the standard deviation calculation, `STDDEV.P` and `STDDEV.S`.\n",
    "The `STDDEV.P` function performs the above calculation but in the `STDDEV.S` calculation the division is by `len(x)-1` rather than `len(x)`. \n",
    "- Research these Excel functions, writing a note in a Markdown cell about the difference between them. Then use numpy to perform a simulation demonstrating that the `STDDEV.S` calculation is a better estimate for the standard deviation of a population when performed on a sample. \n",
    "Note that part of this task is to figure out the terminology in the previous sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will look up the Microsoft documentation first.\n",
    "The standard deviation is a measure of how widely values are dispersed from the average value (the mean).\n",
    "\n",
    "The [STDEV function](https://support.microsoft.com/en-us/office/stdev-function-51fecaaa-231e-4bbb-9230-33650a72c9b0) estimates standard deviation based on a sample. According to the documentation, this function has been replaced with one or more new functions that may provide improved accuracy and whose names better reflect their usage.\n",
    "- The [STDDEV.S function](https://support.microsoft.com/en-us/office/stdev-s-function-7d69cf97-0c1f-4acf-be27-f3e83904cc23) estimates standard deviation based on a sample (ignores logical values and text in the sample).\n",
    "`STDEV.S` assumes that its arguments are a sample of the population. The standard deviation is calculated using the \"n-1\" method. If your data represents the entire population, then compute the standard deviation using `STDEV.P`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The aim of statistics is to make statements about the population using a sample. Therefore it is important to establish the relationship between the sample and the population.\n",
    "A parameter is a population characterestic while a sample statistic is any quantity computed from  values in the sample. The sample is just one of many that can be drawn from a population. While the value of a population parameter is fixed, the value of a statistic varies from sample to sample. It is a random variable and it's probability distribution known as its sampling distribution.\n",
    "\n",
    "The standard deviation is the most commonly used measure of the dispersion of a data set. It is the square root of the variance. The larger the standard deviation, the greater the spread of the data. The variance is the average of the squared difference (of each data point) from the mean.\n",
    "$n-1$ is used in the sample variance formula instead of n because using n tends to produce an underestimate of the population variance. For this reason n-1 is used to provide the appropriate correction for this tendency.\n",
    "\n",
    "\n",
    "The population variance is calculated using the formula:\n",
    "$$\\sigma^2\\frac{=\\sum(x_i-\\mu)^2}{n}$$\n",
    "\n",
    "The sample variance is calculated using the formula:\n",
    "\n",
    "$$S^2\\frac{=\\sum(x_i-\\bar{x})^2}{n-1}$$\n",
    "\n",
    "\n",
    "According to wikipedia,  using $n−1$ instead of $n$ in the formula for the sample variance and sample standard deviation is known as [Bessel's Correction](https://en.wikipedia.org/wiki/Bessel%27s_correction). The technique is named after Friedrick Bessel. $n$ refers to the number of observations in a sample.\n",
    ">This method corrects the bias in the estimation of the population variance. It also partially corrects the bias in the estimation of the population standard deviation. However, the correction often increases the mean squared error in these estimations.\n",
    ">In estimating the population variance from a sample when the population mean is unknown, the uncorrected sample variance is the mean of the squares of deviations of sample values from the sample mean (i.e. using a multiplicative factor 1/n). In this case, the sample variance is a biased estimator of the population variance.\n",
    "Multiplying the uncorrected sample variance by the factor $\\frac{n}{n-1}$ gives an unbiased estimator of the population variance\n",
    "\n",
    "\n",
    "- Bessel's correction is the degrees of freedom in the residuals vector \n",
    "$x_1-\\bar{x},...,x_n - \\bar{x}$ where $\\bar{x}$ is the sample mean. There are $n$ independent observations in the sample but only $n-1$ residuals because they sum to one.\n",
    "\n",
    "Generally Bessel's correction is an approach to reduce the bias due to finite sample size.\n",
    "\n",
    "---\n",
    "If you have a population of size N and take a sample of n from the population. \n",
    "The population mean takes the sum of every data point in the population and divide by the number of observations ($n$ data points) to get the population mean which is denoted by $\\mu$.\n",
    "The sample mean is the sum of the observations in a sample divided by the number of observations. This is usually denoted by $\\bar{x}$\n",
    "You then consider the dispersion of the data points from the mean. \n",
    "The mean of the squared distances from the population mean divided by the total number of data points in the population.\n",
    "There are several ways to calculate the sample variance. The **biased** sample variance is a non-unbiased estimator of the population variance and is usually denoted by $S_n$. \n",
    "\n",
    "From every one of the $n$ data points in the sample you substract the sample mean $\\bar{x}$ and divide by the number of data points $n$. To get the **unbiased** estimate we instead divide by $n-1$. As $n-1$ is a smaller number than $n$, then dividing by the smaller number will give a larger value. This unbiased estimate is usually denoted by $S_{n-1}$.\n",
    "\n",
    "(Often assume that when people refer to $S^2$ that they are referring to the unbiased estimate).\n",
    "\n",
    "An example of this would be taking a all the data in a population plotted on the number line. If a sample is taken from this then the sample mean of this sample could be very close to the population mean or then again it might not, depending on what sample of data points is taken. When you take a sample, its sample mean value will always fall inside the sample but the population mean could be outside of this. Therefore you could have a much lower estimate than the true variance from the actual population mean. Depending on what the sample values are and if they come from one end or other of the population, then the true population mean might be outside of the sample taken and then you are likely to be underestimating the true population variance.\n",
    "\n",
    "If we had all the data in a population plotted on a number line, if a sample is taken from this.\n",
    "N = 14. take a sample n=3. depending on which 3 points in the sample, the sample mean could be very close to the population mean. There is also a distinct possibility that it won't. The key idea is that when you take a sample, the sample mean will always sit within your sample so there is a real possibility that when you take your sample, the mean could be outside this sample. It could be a much lower estimate than the true variance from the actual population mean. (The sample mean will always sit inside the data but the sample \n",
    "Therefore dividing by $n-1$ instead of $n$ will give a slightly larger sample variance and this  will be an unbiased estimate.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation using Numpy to demonstrate.\n",
    "The tasks requires using numpy to perform a simulation demonstrating that the `STDDEV.S` calculation is a better estimate for the standard deviation of a population when performed on a sample. \n",
    "\n",
    "`np.sqrt(np.sum((x - np.mean(x))**2)/len(x))`\n",
    "\n",
    "$$frac{\\sqrt{\\sum{x=\\bar{x}}}{n}$$\n",
    "\n",
    "The variance calculation for the population uses $n$ while the variance calculation for the sample using $n-1$.\n",
    "The population variance is calculated using the formula:\n",
    "$$\\sigma^2\\frac{=\\sum(x_i-\\mu)^2}{n}$$\n",
    "\n",
    "The sample variance is calculated using the formula:\n",
    "\n",
    "$$S^2\\frac{=\\sum(x_i-\\bar{x})^2}{n-1}$$\n",
    "\n",
    "The standard deviation is the square root of the variance.\n",
    "\n",
    "So I need to simulate a population using numpy random, then decide on the size of the sample, then from the population select some samples of and calculate the statistics of the samples. Calculate the sample variance of each of the samples using both $n$ and $n-1$ and then take the mean of the variances calculated using $n$ and $n-1$. We should expect to see that when using $n$ instead of $n-1$ that the true variance is still being underestimated. When using $n-1$ the true variance should be closer to the true population variance,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 References\n",
    "\n",
    "- [Wikipedia on Bessels Correction](https://en.wikipedia.org/wiki/Bessel%27s_correction)\n",
    "- Some old statistics notes from UCD\n",
    "- [Khan Academy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "More reference above to bring down and include here\n",
    "- https://www.latex-tutorial.com/tutorials/amsmath/\n",
    "- https://www.math-linux.com/latex-26/faq/latex-faq/article/latex-natural-numbers\n",
    "- https://en.wikibooks.org/wiki/LaTeX/Mathematics\n",
    "\n",
    "Read https://kodlogs.com/blog/715/convert-scientific-notation-to-decimal-python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
